{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in e:\\thesis\\.venv\\lib\\site-packages (2.1.0)\n",
      "Requirement already satisfied: transformers in e:\\thesis\\.venv\\lib\\site-packages (4.34.1)\n",
      "Requirement already satisfied: sentencepiece in e:\\thesis\\.venv\\lib\\site-packages (0.1.99)\n",
      "Requirement already satisfied: sacrebleu in e:\\thesis\\.venv\\lib\\site-packages (2.3.1)\n",
      "Requirement already satisfied: bert_score in e:\\thesis\\.venv\\lib\\site-packages (0.3.13)\n",
      "Requirement already satisfied: rouge_score in e:\\thesis\\.venv\\lib\\site-packages (0.1.2)\n",
      "Requirement already satisfied: datasets in e:\\thesis\\.venv\\lib\\site-packages (2.14.5)\n",
      "Requirement already satisfied: tensorflow-text in e:\\thesis\\.venv\\lib\\site-packages (2.10.0)\n",
      "Collecting sentence_splitter\n",
      "  Downloading sentence_splitter-1.4-py2.py3-none-any.whl (44 kB)\n",
      "     ---------------------------------------- 0.0/45.0 kB ? eta -:--:--\n",
      "     ---------------------------------------- 45.0/45.0 kB 1.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: filelock in e:\\thesis\\.venv\\lib\\site-packages (from torch) (3.12.4)\n",
      "Requirement already satisfied: typing-extensions in e:\\thesis\\.venv\\lib\\site-packages (from torch) (4.8.0)\n",
      "Requirement already satisfied: sympy in e:\\thesis\\.venv\\lib\\site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in e:\\thesis\\.venv\\lib\\site-packages (from torch) (3.2)\n",
      "Requirement already satisfied: jinja2 in e:\\thesis\\.venv\\lib\\site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in e:\\thesis\\.venv\\lib\\site-packages (from torch) (2023.6.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in e:\\thesis\\.venv\\lib\\site-packages (from transformers) (0.17.3)\n",
      "Requirement already satisfied: numpy>=1.17 in e:\\thesis\\.venv\\lib\\site-packages (from transformers) (1.26.1)\n",
      "Requirement already satisfied: packaging>=20.0 in e:\\thesis\\.venv\\lib\\site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in e:\\thesis\\.venv\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in e:\\thesis\\.venv\\lib\\site-packages (from transformers) (2023.10.3)\n",
      "Requirement already satisfied: requests in e:\\thesis\\.venv\\lib\\site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.15,>=0.14 in e:\\thesis\\.venv\\lib\\site-packages (from transformers) (0.14.1)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in e:\\thesis\\.venv\\lib\\site-packages (from transformers) (0.4.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in e:\\thesis\\.venv\\lib\\site-packages (from transformers) (4.66.1)\n",
      "Requirement already satisfied: portalocker in e:\\thesis\\.venv\\lib\\site-packages (from sacrebleu) (2.8.2)\n",
      "Requirement already satisfied: tabulate>=0.8.9 in e:\\thesis\\.venv\\lib\\site-packages (from sacrebleu) (0.9.0)\n",
      "Requirement already satisfied: colorama in e:\\thesis\\.venv\\lib\\site-packages (from sacrebleu) (0.4.6)\n",
      "Requirement already satisfied: lxml in e:\\thesis\\.venv\\lib\\site-packages (from sacrebleu) (4.9.3)\n",
      "Requirement already satisfied: pandas>=1.0.1 in e:\\thesis\\.venv\\lib\\site-packages (from bert_score) (2.1.1)\n",
      "Requirement already satisfied: matplotlib in e:\\thesis\\.venv\\lib\\site-packages (from bert_score) (3.8.0)\n",
      "Requirement already satisfied: absl-py in e:\\thesis\\.venv\\lib\\site-packages (from rouge_score) (2.0.0)\n",
      "Requirement already satisfied: nltk in e:\\thesis\\.venv\\lib\\site-packages (from rouge_score) (3.8.1)\n",
      "Requirement already satisfied: six>=1.14.0 in e:\\thesis\\.venv\\lib\\site-packages (from rouge_score) (1.16.0)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in e:\\thesis\\.venv\\lib\\site-packages (from datasets) (13.0.0)\n",
      "Requirement already satisfied: dill<0.3.8,>=0.3.0 in e:\\thesis\\.venv\\lib\\site-packages (from datasets) (0.3.7)\n",
      "Requirement already satisfied: xxhash in e:\\thesis\\.venv\\lib\\site-packages (from datasets) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in e:\\thesis\\.venv\\lib\\site-packages (from datasets) (0.70.15)\n",
      "Requirement already satisfied: aiohttp in e:\\thesis\\.venv\\lib\\site-packages (from datasets) (3.8.6)\n",
      "Requirement already satisfied: tensorflow-hub>=0.8.0 in e:\\thesis\\.venv\\lib\\site-packages (from tensorflow-text) (0.15.0)\n",
      "Requirement already satisfied: tensorflow<2.11,>=2.10.0 in e:\\thesis\\.venv\\lib\\site-packages (from tensorflow-text) (2.10.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in e:\\thesis\\.venv\\lib\\site-packages (from aiohttp->datasets) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in e:\\thesis\\.venv\\lib\\site-packages (from aiohttp->datasets) (3.3.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in e:\\thesis\\.venv\\lib\\site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in e:\\thesis\\.venv\\lib\\site-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in e:\\thesis\\.venv\\lib\\site-packages (from aiohttp->datasets) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in e:\\thesis\\.venv\\lib\\site-packages (from aiohttp->datasets) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in e:\\thesis\\.venv\\lib\\site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in e:\\thesis\\.venv\\lib\\site-packages (from pandas>=1.0.1->bert_score) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in e:\\thesis\\.venv\\lib\\site-packages (from pandas>=1.0.1->bert_score) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in e:\\thesis\\.venv\\lib\\site-packages (from pandas>=1.0.1->bert_score) (2023.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in e:\\thesis\\.venv\\lib\\site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in e:\\thesis\\.venv\\lib\\site-packages (from requests->transformers) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in e:\\thesis\\.venv\\lib\\site-packages (from requests->transformers) (2023.7.22)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in e:\\thesis\\.venv\\lib\\site-packages (from tensorflow<2.11,>=2.10.0->tensorflow-text) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in e:\\thesis\\.venv\\lib\\site-packages (from tensorflow<2.11,>=2.10.0->tensorflow-text) (23.5.26)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in e:\\thesis\\.venv\\lib\\site-packages (from tensorflow<2.11,>=2.10.0->tensorflow-text) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in e:\\thesis\\.venv\\lib\\site-packages (from tensorflow<2.11,>=2.10.0->tensorflow-text) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in e:\\thesis\\.venv\\lib\\site-packages (from tensorflow<2.11,>=2.10.0->tensorflow-text) (3.10.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in e:\\thesis\\.venv\\lib\\site-packages (from tensorflow<2.11,>=2.10.0->tensorflow-text) (1.1.2)\n",
      "Requirement already satisfied: libclang>=13.0.0 in e:\\thesis\\.venv\\lib\\site-packages (from tensorflow<2.11,>=2.10.0->tensorflow-text) (16.0.6)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in e:\\thesis\\.venv\\lib\\site-packages (from tensorflow<2.11,>=2.10.0->tensorflow-text) (3.3.0)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in e:\\thesis\\.venv\\lib\\site-packages (from tensorflow<2.11,>=2.10.0->tensorflow-text) (3.19.6)\n",
      "Requirement already satisfied: setuptools in e:\\thesis\\.venv\\lib\\site-packages (from tensorflow<2.11,>=2.10.0->tensorflow-text) (58.1.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in e:\\thesis\\.venv\\lib\\site-packages (from tensorflow<2.11,>=2.10.0->tensorflow-text) (2.3.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in e:\\thesis\\.venv\\lib\\site-packages (from tensorflow<2.11,>=2.10.0->tensorflow-text) (1.15.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in e:\\thesis\\.venv\\lib\\site-packages (from tensorflow<2.11,>=2.10.0->tensorflow-text) (0.31.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in e:\\thesis\\.venv\\lib\\site-packages (from tensorflow<2.11,>=2.10.0->tensorflow-text) (1.59.0)\n",
      "Requirement already satisfied: tensorboard<2.11,>=2.10 in e:\\thesis\\.venv\\lib\\site-packages (from tensorflow<2.11,>=2.10.0->tensorflow-text) (2.10.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.11,>=2.10.0 in e:\\thesis\\.venv\\lib\\site-packages (from tensorflow<2.11,>=2.10.0->tensorflow-text) (2.10.0)\n",
      "Requirement already satisfied: keras<2.11,>=2.10.0 in e:\\thesis\\.venv\\lib\\site-packages (from tensorflow<2.11,>=2.10.0->tensorflow-text) (2.10.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in e:\\thesis\\.venv\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in e:\\thesis\\.venv\\lib\\site-packages (from matplotlib->bert_score) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in e:\\thesis\\.venv\\lib\\site-packages (from matplotlib->bert_score) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in e:\\thesis\\.venv\\lib\\site-packages (from matplotlib->bert_score) (4.43.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in e:\\thesis\\.venv\\lib\\site-packages (from matplotlib->bert_score) (1.4.5)\n",
      "Requirement already satisfied: pillow>=6.2.0 in e:\\thesis\\.venv\\lib\\site-packages (from matplotlib->bert_score) (10.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in e:\\thesis\\.venv\\lib\\site-packages (from matplotlib->bert_score) (3.1.1)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in e:\\thesis\\.venv\\lib\\site-packages (from matplotlib->bert_score) (6.1.0)\n",
      "Requirement already satisfied: click in e:\\thesis\\.venv\\lib\\site-packages (from nltk->rouge_score) (8.1.7)\n",
      "Requirement already satisfied: joblib in e:\\thesis\\.venv\\lib\\site-packages (from nltk->rouge_score) (1.3.2)\n",
      "Requirement already satisfied: pywin32>=226 in e:\\thesis\\.venv\\lib\\site-packages (from portalocker->sacrebleu) (306)\n",
      "Requirement already satisfied: mpmath>=0.19 in e:\\thesis\\.venv\\lib\\site-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in e:\\thesis\\.venv\\lib\\site-packages (from astunparse>=1.6.0->tensorflow<2.11,>=2.10.0->tensorflow-text) (0.41.2)\n",
      "Requirement already satisfied: zipp>=3.1.0 in e:\\thesis\\.venv\\lib\\site-packages (from importlib-resources>=3.2.0->matplotlib->bert_score) (3.17.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in e:\\thesis\\.venv\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow<2.11,>=2.10.0->tensorflow-text) (2.23.3)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in e:\\thesis\\.venv\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow<2.11,>=2.10.0->tensorflow-text) (0.4.6)\n",
      "Requirement already satisfied: markdown>=2.6.8 in e:\\thesis\\.venv\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow<2.11,>=2.10.0->tensorflow-text) (3.5)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in e:\\thesis\\.venv\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow<2.11,>=2.10.0->tensorflow-text) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in e:\\thesis\\.venv\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow<2.11,>=2.10.0->tensorflow-text) (1.8.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in e:\\thesis\\.venv\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow<2.11,>=2.10.0->tensorflow-text) (3.0.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in e:\\thesis\\.venv\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow<2.11,>=2.10.0->tensorflow-text) (5.3.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in e:\\thesis\\.venv\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow<2.11,>=2.10.0->tensorflow-text) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in e:\\thesis\\.venv\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow<2.11,>=2.10.0->tensorflow-text) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in e:\\thesis\\.venv\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow<2.11,>=2.10.0->tensorflow-text) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in e:\\thesis\\.venv\\lib\\site-packages (from markdown>=2.6.8->tensorboard<2.11,>=2.10->tensorflow<2.11,>=2.10.0->tensorflow-text) (6.8.0)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in e:\\thesis\\.venv\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow<2.11,>=2.10.0->tensorflow-text) (0.5.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in e:\\thesis\\.venv\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow<2.11,>=2.10.0->tensorflow-text) (3.2.2)\n",
      "Installing collected packages: sentence_splitter\n",
      "Successfully installed sentence_splitter-1.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: There was an error checking the latest version of pip.\n"
     ]
    }
   ],
   "source": [
    "!pip install torch transformers sentencepiece sacrebleu bert_score rouge_score datasets tensorflow-text sentence_splitter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ThanhJamieAI/FPT_Paraphrase\n",
    "#### ThanhJamieAI/Thanh_ParaphraseV3\n",
    "#### ThanhJamieAI/ParapharseV8_8E_4B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from transformers import PegasusForConditionalGeneration, PegasusTokenizer\n",
    "import sentencepiece\n",
    "import torch\n",
    "from sentence_splitter import SentenceSplitter\n",
    "import evaluate\n",
    "\n",
    "model_name = \"ThanhJamieAI/ParapharseV8_8E_4B\"\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "tokenizer = PegasusTokenizer.from_pretrained(model_name)\n",
    "model = PegasusForConditionalGeneration.from_pretrained(model_name).to(device)\n",
    "bleu = evaluate.load('bleu') # 'bleu': 1.0, 'precisions': [1.0, 1.0, 1.0, 1.0], 'brevity_penalty': 1.0, 'length_ratio': 1.1666666666666667, 'translation_length': 7, 'reference_length': 6}\n",
    "ter = evaluate.load('ter') # {'score': ter_score, 'num_edits': num_edits, 'ref_length': ref_length}\n",
    "rouge = evaluate.load('rouge') # ['rouge1', 'rouge2', 'rougeL', 'rougeLsum']\n",
    "meteor = evaluate.load('meteor')  # Its values range from 0 to 1\n",
    "sacrebleu = evaluate.load('sacrebleu') # score: BLEU score | counts: Counts | totals: Totals | precisions: Precisions | bp: Brevity penalty | sys_len: predictions length | ref_len: reference length\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Where do they get a random paragraph? Where do they get a random paragraph? Do you think they've written a random paragraph? Do they just write a random paragraph? At this moment, he read the random paragraph and realized it was about random paragraphs and his world would never be the same. At that moment, he looked back at the random paragraph and realized it was about random paragraphs and his world would never be the same.\n"
     ]
    }
   ],
   "source": [
    "# Ví dụ sử dụng:\n",
    "splitter = SentenceSplitter(language='en')\n",
    "text = \"Where do they get a random paragraph? he wondered as he clicked the generate button. Do they just write a random paragraph or do they get it somewhere? At that moment he read the random paragraph and realized it was about random paragraphs and his world would never be the same.\"\n",
    "sentence_list = splitter.split(text)\n",
    "\n",
    "batch = tokenizer(sentence_list,truncation=True, padding='longest', max_length=100, return_tensors=\"pt\").to(device)\n",
    "translated = model.generate(**batch, max_length=1024, num_beams=10, num_return_sequences=2, temperature=1.5, do_sample = True)\n",
    "tgt_text = tokenizer.batch_decode(translated, skip_special_tokens=True)\n",
    "paraphrased_text = \" \".join(tgt_text)\n",
    "print(paraphrased_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"She didn't understand how changed worked.\",\n",
       " 'When she looked at today compared to yesterday, there was nothing that she could see that was different.',\n",
       " \"Yet, when she looked at today compared to last year, she couldn't see how anything was ever the same.\"]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splitter = SentenceSplitter(language='en')\n",
    "text = \"She didn't understand how changed worked. When she looked at today compared to yesterday, there was nothing that she could see that was different. Yet, when she looked at today compared to last year, she couldn't see how anything was ever the same.\"\n",
    "sentence_list = splitter.split(text)\n",
    "sentence_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentence_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = tokenizer(sentence_list,truncation=True, padding='longest', max_length=100, return_tensors=\"pt\").to(device)\n",
    "translated = model.generate(**batch, max_length=1024, num_beams=3, num_return_sequences=3, temperature=1.5, do_sample = True)\n",
    "tgt_text = tokenizer.batch_decode(translated, skip_special_tokens=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def demo(sentence_list, num_return_sequences, num_beams,temperature,do_sample, input_string):\n",
    "    dict_in_dict  = {}\n",
    "    max_sentence_output = int(num_return_sequences * len(sentence_list))\n",
    "    batch = tokenizer(sentence_list,truncation=True, padding='longest', max_length=100, return_tensors=\"pt\").to(device)\n",
    "    translated = model.generate(**batch, max_length=1024, num_beams=num_beams, num_return_sequences=num_return_sequences, temperature=temperature, do_sample = do_sample)\n",
    "    tgt_text = tokenizer.batch_decode(translated, skip_special_tokens=True)\n",
    "    for i in range(0,num_return_sequences,1):\n",
    "        merged_strings = []\n",
    "        for a in range(i,max_sentence_output,num_return_sequences):\n",
    "            text = \"\".join(tgt_text[a])\n",
    "            merged_strings.append(\"\".join(tgt_text[a]))\n",
    "        paraphrased_text = \" \".join(merged_strings)\n",
    "        BLUE_score,TER_score,ROUGE_score,METEOR_score,SACREBLUE_score = eval(predict_text= paraphrased_text, reference_text= input_string)\n",
    "        dict_in_dict[i] = {\n",
    "        \"text\": f\"{paraphrased_text}\",\n",
    "        \"BLUE_score\": BLUE_score['bleu'],\n",
    "        \"TER_score\": TER_score['score'],\n",
    "        \"ROUGE1_score\": ROUGE_score['rouge1'],\n",
    "        \"ROUGEL_score\": ROUGE_score['rougeL'],\n",
    "        \"METEOR_score\": METEOR_score['meteor'],\n",
    "        \"SACREBLUE_score\": SACREBLUE_score['score'],\n",
    "    }\n",
    "        \n",
    "    return dict_in_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def eval(predict_text, reference_text):\n",
    "\n",
    "    BLUE_score = bleu.compute(**{\n",
    "        'predictions': [predict_text],\n",
    "        'references': [reference_text]\n",
    "    })\n",
    "    TER_score = ter.compute(**{\n",
    "        'predictions': [predict_text],\n",
    "        'references': [reference_text]\n",
    "    })\n",
    "    ROUGE_score = rouge.compute(**{\n",
    "        'predictions': [predict_text],\n",
    "        'references': [reference_text]\n",
    "    })\n",
    "    METEOR_score = meteor.compute(**{\n",
    "        'predictions': [predict_text],\n",
    "        'references': [reference_text]\n",
    "    })\n",
    "    SACREBLUE_score = sacrebleu.compute(**{\n",
    "        'predictions': [predict_text],\n",
    "        'references': [reference_text]\n",
    "    })\n",
    "\n",
    "    return BLUE_score, TER_score, ROUGE_score, METEOR_score, SACREBLUE_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_string = input()\n",
    "splitter = SentenceSplitter(language='en')\n",
    "sentence_list = splitter.split(input_string)\n",
    "output_dict = demo(sentence_list,10,10,1.5,True,input_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {'text': \"Where did they get a random paragraph? They're writing a random paragraph, or do they get it somewhere? At that moment, he read the random paragraph and realized it was about random paragraphs and his world would never be the same.\",\n",
       "  'BLUE_score': 0.6133577802233244,\n",
       "  'TER_score': 31.372549019607842,\n",
       "  'ROUGE1_score': 0.8387096774193549,\n",
       "  'ROUGEL_score': 0.8387096774193549,\n",
       "  'METEOR_score': 0.7969403863748856,\n",
       "  'SACREBLUE_score': 61.33577802233245},\n",
       " 1: {'text': 'Where did they get a random paragraph? Or did they just write a random paragraph? At that moment, he read the random paragraph and realized it was about random paragraphs and his world would never be the same.',\n",
       "  'BLUE_score': 0.5465181909576255,\n",
       "  'TER_score': 37.254901960784316,\n",
       "  'ROUGE1_score': 0.8089887640449439,\n",
       "  'ROUGEL_score': 0.7865168539325842,\n",
       "  'METEOR_score': 0.748126551219948,\n",
       "  'SACREBLUE_score': 54.65181909576255},\n",
       " 2: {'text': \"Where did they get a random paragraph? They're writing a random paragraph, or they're just writing a random paragraph, or did they get it somewhere? At that moment, he looked back at the random paragraph and realized it was about random paragraphs and his life would never be the same.\",\n",
       "  'BLUE_score': 0.5075558994321766,\n",
       "  'TER_score': 39.21568627450981,\n",
       "  'ROUGE1_score': 0.7184466019417477,\n",
       "  'ROUGEL_score': 0.7184466019417477,\n",
       "  'METEOR_score': 0.7519213040038957,\n",
       "  'SACREBLUE_score': 50.755589943217664},\n",
       " 3: {'text': \"Where did they get a random paragraph? They're writing a random paragraph, or they're just writing a paragraph, or did they get it somewhere? At that moment, he looked back at the random paragraph and realized it was about random paragraphs and his life would never be the same.\",\n",
       "  'BLUE_score': 0.5077311252070118,\n",
       "  'TER_score': 41.17647058823529,\n",
       "  'ROUGE1_score': 0.7254901960784313,\n",
       "  'ROUGEL_score': 0.7058823529411765,\n",
       "  'METEOR_score': 0.7383766722678059,\n",
       "  'SACREBLUE_score': 50.773112520701204},\n",
       " 4: {'text': \"Where do they get a random paragraph? They're writing a random paragraph, or do they think they're getting it somewhere? At that moment, he looked back at the random paragraph and realized it was about random paragraphs and his life would never be the same.\",\n",
       "  'BLUE_score': 0.5191738977096423,\n",
       "  'TER_score': 43.13725490196079,\n",
       "  'ROUGE1_score': 0.7551020408163265,\n",
       "  'ROUGEL_score': 0.7551020408163265,\n",
       "  'METEOR_score': 0.7345144292729082,\n",
       "  'SACREBLUE_score': 51.9173897709642},\n",
       " 5: {'text': \"Where do they get a random paragraph? They've written a random paragraph, but what they think is they've written? At that moment, he saw the random paragraph and realized it was about random paragraphs and his world would never be the same.\",\n",
       "  'BLUE_score': 0.5089345713048037,\n",
       "  'TER_score': 43.13725490196079,\n",
       "  'ROUGE1_score': 0.7157894736842105,\n",
       "  'ROUGEL_score': 0.7157894736842105,\n",
       "  'METEOR_score': 0.6921840466144263,\n",
       "  'SACREBLUE_score': 50.89345713048035},\n",
       " 6: {'text': \"Where do they get a random paragraph? They're writing a random paragraph, or they're just writing a paragraph, or they're really trying to catch it. At that moment, he saw the random paragraph and realized it was about random paragraphs and his world would never be the same.\",\n",
       "  'BLUE_score': 0.5063367577977645,\n",
       "  'TER_score': 43.13725490196079,\n",
       "  'ROUGE1_score': 0.7254901960784313,\n",
       "  'ROUGEL_score': 0.7058823529411765,\n",
       "  'METEOR_score': 0.7082428931168427,\n",
       "  'SACREBLUE_score': 50.633675779776475},\n",
       " 7: {'text': \"Where do they get a random paragraph? They've written a random paragraph, but what they think is they've got it somewhere? At that moment, he saw the random paragraph and realized it was about random paragraphs and his world would never be the same.\",\n",
       "  'BLUE_score': 0.5488584962360801,\n",
       "  'TER_score': 39.21568627450981,\n",
       "  'ROUGE1_score': 0.7422680412371134,\n",
       "  'ROUGEL_score': 0.7422680412371134,\n",
       "  'METEOR_score': 0.7455363526792098,\n",
       "  'SACREBLUE_score': 54.88584962360802},\n",
       " 8: {'text': 'Where do they get a random paragraph? Do they catch up with it, or do they get it somewhere? At that moment, he thought it was about random paragraphs and that moment he would never be the same.',\n",
       "  'BLUE_score': 0.44639630604415204,\n",
       "  'TER_score': 45.09803921568628,\n",
       "  'ROUGE1_score': 0.6966292134831461,\n",
       "  'ROUGEL_score': 0.6741573033707866,\n",
       "  'METEOR_score': 0.6136649734633072,\n",
       "  'SACREBLUE_score': 44.63963060441519},\n",
       " 9: {'text': \"Where do they get a random paragraph? They're writing a random paragraph, or they're just writing a paragraph, or they're trying to catch it somewhere. At that moment, he thought it was about random paragraphs and that moment he would never be the same.\",\n",
       "  'BLUE_score': 0.35770124945828313,\n",
       "  'TER_score': 54.90196078431373,\n",
       "  'ROUGE1_score': 0.673469387755102,\n",
       "  'ROUGEL_score': 0.6122448979591838,\n",
       "  'METEOR_score': 0.6065897641202126,\n",
       "  'SACREBLUE_score': 35.770124945828314}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\THESIS\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from comet_ml import Experiment\n",
    "from tqdm.auto import tqdm\n",
    "from datasets import load_metric\n",
    "\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow as tf\n",
    "import tensorflow_text as text  # Needed for loading universal-sentence-encoder-cmlm/multilingual-preprocess\n",
    "import numpy as np\n",
    "\n",
    "from transformers import PegasusForConditionalGeneration, PegasusTokenizer, get_cosine_schedule_with_warmup, get_constant_schedule_with_warmup\n",
    "from transformers.models.bart.modeling_bart import shift_tokens_right\n",
    "# from transformers import T5ForConditionalGeneration, T5Tokenizer, PegasusForConditionalGeneration, PegasusTokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def read_dataset(path):\n",
    "  dataframe = pd.read_parquet(path)\n",
    "  return dataframe[['#1 String', '#2 String']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#1 String</th>\n",
       "      <th>#2 String</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Amrozi accused his brother, whom he called \"th...</td>\n",
       "      <td>Referring to him as only \"the witness\", Amrozi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>They had published an advertisement on the Int...</td>\n",
       "      <td>On June 10, the ship's owners had published an...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Revenue in the first quarter of the year dropp...</td>\n",
       "      <td>With the scandal hanging over Stewart's compan...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The DVD-CCA then appealed to the state Supreme...</td>\n",
       "      <td>The DVD CCA appealed that decision to the U.S....</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>He said the foodservice pie business doesn't f...</td>\n",
       "      <td>\"The foodservice pie business does not fit our...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194326</th>\n",
       "      <td>Caffiers is a commune . It is found in the reg...</td>\n",
       "      <td>Caffiers is a commune in the Pas-de-Calais dep...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194327</th>\n",
       "      <td>549 people were living in Orange as of 2000 .</td>\n",
       "      <td>The population was 549 at the 2000 census .</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194328</th>\n",
       "      <td>Orange is a town of Juneau County in the state...</td>\n",
       "      <td>Orange is a town in Juneau County , Wisconsin ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194329</th>\n",
       "      <td>Orainville is a commune . It is found in the r...</td>\n",
       "      <td>Orainville is a commune in the Aisne departmen...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194330</th>\n",
       "      <td>A text editor is a program that is run on a co...</td>\n",
       "      <td>A text editor is a type of program used for ed...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>194331 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                #1 String  \\\n",
       "0       Amrozi accused his brother, whom he called \"th...   \n",
       "1       They had published an advertisement on the Int...   \n",
       "2       Revenue in the first quarter of the year dropp...   \n",
       "3       The DVD-CCA then appealed to the state Supreme...   \n",
       "4       He said the foodservice pie business doesn't f...   \n",
       "...                                                   ...   \n",
       "194326  Caffiers is a commune . It is found in the reg...   \n",
       "194327      549 people were living in Orange as of 2000 .   \n",
       "194328  Orange is a town of Juneau County in the state...   \n",
       "194329  Orainville is a commune . It is found in the r...   \n",
       "194330  A text editor is a program that is run on a co...   \n",
       "\n",
       "                                                #2 String  label  \n",
       "0       Referring to him as only \"the witness\", Amrozi...      1  \n",
       "1       On June 10, the ship's owners had published an...      1  \n",
       "2       With the scandal hanging over Stewart's compan...      1  \n",
       "3       The DVD CCA appealed that decision to the U.S....      1  \n",
       "4       \"The foodservice pie business does not fit our...      1  \n",
       "...                                                   ...    ...  \n",
       "194326  Caffiers is a commune in the Pas-de-Calais dep...      1  \n",
       "194327        The population was 549 at the 2000 census .      1  \n",
       "194328  Orange is a town in Juneau County , Wisconsin ...      1  \n",
       "194329  Orainville is a commune in the Aisne departmen...      1  \n",
       "194330  A text editor is a type of program used for ed...      1  \n",
       "\n",
       "[194331 rows x 3 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train['#1 String'] = dataset_train['#1 String'].astype('str')\n",
    "dataset_train['#2 String'] = dataset_train['#2 String'].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random_ilocs = random.sample(list(dataset_train.index), 40000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdata = dataset_train.iloc[random_ilocs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdata.to_parquet('train_quality_dataset_40k.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataaaaa = pd.read_parquet('../train_quality_dataset222.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import PegasusForConditionalGeneration, PegasusTokenizer \n",
    "from transformers.models.bart.modeling_bart import shift_tokens_right\n",
    "model = PegasusForConditionalGeneration.from_pretrained('ThanhJamieAI/ParapharseV8_8E_4B')\n",
    "tokenizer = PegasusTokenizer.from_pretrained('ThanhJamieAI/ParapharseV8_8E_4B')\n",
    "dataset_train = dataaaaa\n",
    "data_x = tokenizer(dataset_train['#1 String'].tolist(), padding='max_length',\n",
    "                 max_length=dataset_train['#1 String'].map(lambda x: len(x)).max(), return_tensors='pt')\n",
    "\n",
    "data_y = None\n",
    "\n",
    "with tokenizer.as_target_tokenizer():\n",
    "  data_y = tokenizer(dataset_train['#2 String'].tolist(), padding='max_length',\n",
    "                          max_length=dataset_train['#2 String'].map(lambda x: len(x)).max(), return_tensors='np')\n",
    "data_y = data_y['input_ids']\n",
    "data_y[data_y == model.config.pad_token_id] = -100\n",
    "\n",
    "data_x['labels'] = torch.tensor(data_y)\n",
    "\n",
    "data_x['decoder_input_ids'] = shift_tokens_right(data_x['labels'], model.config.pad_token_id, model.config.decoder_start_token_id)\n",
    "\n",
    "data_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
